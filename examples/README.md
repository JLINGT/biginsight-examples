See the README file in each project for instructions how to run the example.

*********************************************************************

#### Hdfs (Using Knox API - WebHDFS)

##### *Groovy*

- List folder contents using Groovy [[WebHdfsGroovy](./WebHdfsGroovy/)]
- Create a folder using Groovy [[WebHdfsGroovy](./WebHdfsGroovy/)]
- Upload a file using Groovy [[WebHdfsGroovy](./WebHdfsGroovy/)]

##### *cURL*

- List folder contents using cURL [[WebHdfsCurl](./WebHdfsCurl/)]
- Create a folder using cURL [[WebHdfsCurl](./WebHdfsCurl/)]
- Upload a file using cURL [[WebHdfsCurl](./WebHdfsCurl/)]

*********************************************************************

#### Ambari

- Get cluster name and then services installed on cluster [[Ambari](./Ambari)]
- Perform HDFS Service Check via Ambari REST [[Ambari](./Ambari)]

*********************************************************************

#### BigR 

- Connect to BigR (requires R installed locally) [[BigR](./BigR)]

*********************************************************************

#### BigSQL

- Connect to Big SQL from Groovy [[BigSQLGroovy](./BigSQLGroovy)]
- Insert/Select with Big SQL from Groovy [[BigSQLGroovy](./BigSQLGroovy)]
- Load/Select with Big SQL from Groovy [[BigSQLGroovy](./BigSQLGroovy)]
- Connect to Big SQL from Java [[BigSQLJava](./BigSQLJava)]

*********************************************************************

#### Hive

- Connect to Hive from Groovy [[HiveGroovy](./HiveGroovy)]
- Connect to Hive from Java  [[HiveJava](./HiveJava)]
- Start a Hive Beeline Session [[HiveBeeline](./HiveBeeline)]

*********************************************************************

#### Spark (run in a ssh session on the BigInsights cluster)

- Submit a spark python job [[SparkPythonSsh](./SparkPythonSsh)]
- Submit a spark streaming python job [[SparkStreamingPythonSsh](./SparkStreamingPythonSsh)]

*********************************************************************

#### Oozie (Using Knox API)

- Submit a Java Mapreduce job using Groovy [[OozieWorkflowMapReduce](./OozieWorkflowMapReduce)]
- Submit a Java Mapreduce job using cURL [[OozieWorkflowCurl](./OozieWorkflowCurl)]
- Submit a Java Spark job using Groovy [[OozieWorkflowSpark](./OozieWorkflowSpark)]

*********************************************************************

#### HBase

- Connect to HBase using Groovy [[HBase](./HBase)]
- Manipulate Schema and Perform CRUD Operations using Groovy [[HBaseManipulateSchemaAndPerformCRUD](./HBaseManipulateSchemaAndPerformCRUD)]
- Connect to HBase using Java [[HBaseJava](./HBaseJava)]

*********************************************************************

#### WebHCat/Templeton (Using Knox API)

- Execute a MapReduce Job using Groovy  [[WebHCatMapReduce](./WebHCatMapReduce)]
- Execute a Pig Job using Groovy [[WebHCatPig](./WebHCatPig)]
- Execute a Hive Job using Groovy [[WebHCatHive](./WebHCatHive)]

*********************************************************************

####  Knox

- Run a knox shell client session [[Knoxshell](./Knoxshell)]

*********************************************************************

#### Cloudant

- Pull data from a Cloudant database to HDFS using Spark [[CloudantPullWithSpark](./CloudantPullWithSpark)]
- Push data from HDFS to a Cloudant database using Spark [[CloudantPushWithSpark](./CloudantPushWithSpark)]

*********************************************************************

#### Object Store (Swift, S3)

- Pull data from a object store to HDFS using Spark [[SparkObjectStoreIntegration](./SparkObjectStoreIntegration)]
- Push data from HDFS to a object store using Spark [[SparkObjectStoreIntegration](./SparkObjectStoreIntegration)]

*********************************************************************

#### dashDB

- Pull data from a dashDB database to HDFS using Spark [[DashDBPullWithSpark](./DashDBPullWithSpark)]
- Push data to dashDB database using Spark [[DashDBPushWithSpark](./DashDBPushWithSpark)] 

*********************************************************************

#### Additional scripts

If you would like an example script that has not been included here, please look in the [enhancement issues](https://github.com/snowch/biginsight-examples/issues?q=is%3Aissue+is%3Aopen+label%3Aenhancement) for similar requests.  If a similar request exists, add a comment with your +1.  If a ticket doesn't exist, please create a new one.
