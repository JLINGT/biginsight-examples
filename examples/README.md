See the README file in each project for instructions how to run the example.

*********************************************************************

#### Hdfs (Using Knox API - WebHDFS)

##### *Groovy*

- List folder contents using Groovy [[WebHdfsLs](./WebHdfsLs/)]
- Create a folder using Groovy [[WebHdfsMkdir](./WebHdfsMkdir/)]
- Upload a file using Groovy [[WebHdfsPut](./WebHdfsPut/)]

*********************************************************************

#### BigR 

- Connect to BigR (requires R installed locally) [[BigR](./BigR)]

*********************************************************************

#### BigSQL

- Connect to BigSQL from Groovy [[BigSQL](./BigSQL)]
- Connect to BigSQL from Java [[BigSQLJava](./BigSQLJava)]

*********************************************************************

#### Hive

- Connect to Hive from Groovy [[Hive](./Hive)]
- Connect to Hive from Java  [[HiveJava](./HiveJava)]
- Start a Hive Beeline Session [[HiveBeeline](./HiveBeeline)]

*********************************************************************

#### Spark (run in a ssh session on the BigInsights cluster)

- Submit a spark python job [[SparkPythonSsh](./SparkPythonSsh)]
- Submit a spark streaming python job [[SparkStreamingPythonSsh](./SparkStreamingPythonSsh)]

*********************************************************************

#### Oozie (Using Knox API)

- Execute a Mapreduce job using Oozie [[OozieWorkflowMapReduce](./OozieWorkflowMapReduce)]
- Execute a Spark Java job using Oozie [[OozieWorkflowSpark](./OozieWorkflowSpark)]
- Execute a Spark Python job using Oozie [[OozieWorkflowSparkPython](./OozieWorkflowSparkPython)]

*********************************************************************

#### HBase

- Connect to HBase using Groovy [[HBase](./HBase)]
- Manipulate Schema and Perform CRUD Operations using Groovy [[HBaseSchemaUpdatesAndCRUD](./HBaseSchemaUpdatesAndCRUD)]
- Connect to HBase using Java [[HBaseJava](./HBaseJava)]

*********************************************************************

#### WebHCat/Templeton (Using Knox API)

- Execute a MapReduce Job using Groovy  [[WebHCatMapReduce](./WebHCatMapReduce)]
- Execute a Pig Job using Groovy [[WebHCatPig](./WebHCatPig)]
- Execute a Hive Job using Groovy [[WebHCatHive](./WebHCatHive)]

*********************************************************************

####  Knox

- Run a knox shell client session [[Knoxshell](./Knoxshell)]

*********************************************************************

#### Cloudant

- Pull data from a Cloudant database to HDFS using Spark [[CloudantPullWithSpark](./CloudantPullWithSpark)]
- Push data from HDFS to a Cloudant database using Spark [[CloudantPushWithSpark](./CloudantPushWithSpark)]

*********************************************************************

#### dashDB

- Pull data from a dashDB database to HDFS using Spark [[DashDBPullWithSpark](./DashDBPullWithSpark)]
- Push data to dashDB database using Spark [[DashDBPushWithSpark](./DashDBPushWithSpark)] 

*********************************************************************

#### Additional scripts

If you would like an example script that has not been included here, please look in the [enhancement issues](https://github.com/snowch/biginsight-examples/issues?q=is%3Aissue+is%3Aopen+label%3Aenhancement) for similar requests.  If a similar request exists, add a comment with your +1.  If a ticket doesn't exist, please create a new one.
