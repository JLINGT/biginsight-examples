import javax.net.ssl.*

plugins {
  // we use the ssh plugin to execute actions on the server over ssh
  id 'org.hidetake.ssh' version '1.5.0'
}

Properties props = new Properties()
props.load(new FileInputStream("$projectDir/../../connection.properties"))

// load some common helper methods
apply from: "${projectDir}/../../shared/common-helpers.gradle"

task('CreateTruststore') << {

    delete('./ca_certificate*')
    delete('./es_certificate*')
    delete('./truststore.jks')
    delete('./truststore.jar')

    def host = props.elasticsearch_host
    def port = props.elasticsearch_port
    def cert

    def trustManager = [
        checkClientTrusted: { chain, authType ->  },
        checkServerTrusted: { chain, authType -> cert = chain[0] },
        getAcceptedIssuers: { null }
    ] as X509TrustManager

    def context = SSLContext.getInstance("TLS")
    context.init(null, [trustManager] as TrustManager[], null)
    context.socketFactory.createSocket(host, port as int).with {
        addHandshakeCompletedListener( 
            [ handshakeCompleted: { event -> 
                def cacerts = event.getPeerCertificates() 
                    cacerts.eachWithIndex{ cacert, idx ->

                        // FIXME: use groovy to create the keystore and write the ca certs to it
                        (new File("${projectDir}/ca_certificate_${idx}")).text = 
                                   "-----BEGIN CERTIFICATE-----\n" + \
                                   "${cacert.encoded.encodeBase64(true)}" + \
                                   "-----END CERTIFICATE-----"

                    }   
                } 
            ] as HandshakeCompletedListener
        )
        startHandshake()
        close()
    }

    // FIXME: use groovy to create the keystore and write the ca certs to it
    // in the addHandshakeCompletedListener
    ant.exec(executable: 'keytool', dir:'./') { arg(line: "-import -trustcacerts -alias ca_certificate_0 -file ./ca_certificate_0 -keystore ./truststore.jks -storepass mypassword -noprompt") }
    ant.exec(executable: 'keytool', dir:'./') { arg(line: "-import -trustcacerts -alias ca_certificate_1 -file ./ca_certificate_1 -keystore ./truststore.jks -storepass mypassword -noprompt") }

    def certtext = "-----BEGIN CERTIFICATE-----\n" + \
               "${cert.encoded.encodeBase64(true)}" + \
               "-----END CERTIFICATE-----"

    (new File("${projectDir}/es_certificate")).text = certtext

    // FIXME: use groovy to write the es server cert to the truststore
    ant.exec(executable: 'keytool', dir:'./') {
        arg(line: "-import -trustcacerts -alias es_certificate -file ./es_certificate -keystore ./truststore.jks -storepass mypassword -noprompt")
    }

    ant.exec(executable: 'jar', dir:'./') {
        arg(line: '-cf truststore.jar truststore.jks')
    }
}


task('Example') {

    dependsOn CreateTruststore

    doLast {
        def tmpDir = "test-${new Date().getTime()}"

        def tmpHdfsDir = "/user/${props.username}/${tmpDir}"
        
        // ssh plugin documentation: https://gradle-ssh-plugin.github.io/docs/
        ssh.run {
            // remotes.bicluster is defined in shared/common-helpers.gradle
            session(remotes.bicluster) {

                try {
                    // initialise kerberos
                    execute "kinit -k -t ${props.username}.keytab ${props.username}@IBM.COM"
                } 
                catch (Exception e) {
                    println "problem running kinit - maybe this is a Basic cluster?"
                }

                // create temp local dir for holding sparkscript
                execute "mkdir ${tmpDir}"

                // upload spark script
                put from: "${projectDir}/export_to_elasticsearch.py", into: "${tmpDir}/export_to_elasticsearch.py"
                put from: "${projectDir}/truststore.jar", into: "${tmpDir}/truststore.jar"

                // create temp hdfs folder for holding exported data
                execute "hadoop fs -mkdir ${tmpHdfsDir}"

                def jars = "--jars \"${tmpDir}/truststore.jar\""
                def pkgs = "--packages org.elasticsearch:elasticsearch-spark_2.10:2.3.0"

                def host = props.elasticsearch_host
                def port = props.elasticsearch_port
                def user = props.elasticsearch_user
                def pass = props.elasticsearch_pass

                // execute spark job
                execute "pyspark ${jars} ${pkgs} ${tmpDir}/export_to_elasticsearch.py ${host} ${port} ${user} ${pass} ${tmpDir}"

                // remove temporary hdfs dir
                execute "hadoop fs -rm -r ${tmpHdfsDir}"

                // remove temporary local dir
                execute "rm -rf ${tmpDir}"

                execute "curl -s -u ${user}:${pass} 'https://${host}:${port}/spark/${tmpDir}/_search?pretty=true&q=*:*'"
            
                println "\nSUCCESS >> Successfully TODO"
            }

        }
    }
}
