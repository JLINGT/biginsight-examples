{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook copies all files from a swift object store container to HDFS using WebHDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Utility method to read swift files - don't need to touch this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_hadoop_config(credentials):\n",
    "    prefix = \"fs.swift.service.\" + credentials['name'] \n",
    "    hconf = sc._jsc.hadoopConfiguration()\n",
    "    hconf.set(prefix + \".auth.url\", credentials['auth_url']+'/v2.0/tokens')\n",
    "    hconf.set(prefix + \".auth.endpoint.prefix\", \"endpoints\")\n",
    "    hconf.set(prefix + \".tenant\", credentials['project_id'])\n",
    "    hconf.set(prefix + \".username\", credentials['user_id'])\n",
    "    hconf.set(prefix + \".password\", credentials['password'])\n",
    "    hconf.setInt(prefix + \".http.port\", 8080)\n",
    "    hconf.set(prefix + \".region\", credentials['region'])\n",
    "    hconf.setBoolean(prefix + \".public\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paste your credentials for swift here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    'auth_url' : 'XXXXX',\n",
    "    'project' : 'XXXXX',\n",
    "    'project_id' : 'XXXXX',\n",
    "    'region' : 'XXXXX',\n",
    "    'user_id' : 'XXXXX',\n",
    "    'domain_id' : 'XXXXX',\n",
    "    'domain_name' : 'XXXXX',\n",
    "    'username' : 'XXXXX',\n",
    "    'password' : 'jXXXXX',\n",
    "    'filename' : 'XXXX',\n",
    "    'container' : 'XXXXX',\n",
    "    'tenantId' : 'XXXXX'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your BigInsights details here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bi_host = 'XXXXX'\n",
    "bi_user = 'XXXXX'\n",
    "bi_pass = 'XXXXX'\n",
    "bi_folder = 'XXXXX' # destination folder in hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the swift credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "credentials['name'] = 'keystone'\n",
    "set_hadoop_config(credentials)\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the file from swift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.wholeTextFiles(\"swift://notebooks.\" + credentials['name'] + \"/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the files to webhdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AUTH=(bi_user, bi_pass)\n",
    "\n",
    "KEY=0\n",
    "DATA=1\n",
    "\n",
    "# FIXME! all files get read into memory - may crash with large/lots of files",
    "\n",
    "\n",
    "for item in data.collect():\n",
    "    filename = item[KEY].split('/')[-1]\n",
    "    url = \"{0}/webhdfs/v1/{1}/{2}?op=CREATE\".format(bi_host, bi_folder, filename)\n",
    "    \n",
    "    print(\"started: {0} {1}\".format(filename, url))\n",
    "    \n",
    "    # WARNING! certification verifcation is disabled as per the bluemix\n",
    "    # documentation for curl with the -k flag\n",
    "    \n",
    "    response = requests.put(\n",
    "        url, \n",
    "        auth = AUTH, \n",
    "        data = item[DATA].encode('utf-8'),\n",
    "        verify = False,\n",
    "        headers = { 'Content-Type' : 'text/plain; charset=utf8' }\n",
    "    )\n",
    "    \n",
    "    if not response.status_code == requests.codes.ok:\n",
    "        print(response.content)\n",
    "    \n",
    "    print('completed: ' + filename + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
