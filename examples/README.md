See the README file in each project for instructions how to run the example.

*********************************************************************

#### WebHdfs (Using Knox API)

##### *Groovy*

- List folder contents using Groovy [[WebHdfsLs](./WebHdfsLs/)]
- Create a folder using Groovy [[WebHdfsMkdir](./WebHdfsMkdir/)]
- Upload a file using Groovy [[WebHdfsPut](./WebHdfsPut/)]

##### *Java*

- List folder contents using Java (coming soon ...)
- Create a folder using Java (coming soon ...)
- Upload a file using Java (coming soon ...)

#### BigR 

- Connect to BigR (requires R installed locally) [[BigR](./BigR)]

#### BigSQL

- Connect to BigSQL from Groovy [[BigSQL](./BigSQL)]
- Connect to BigSQL from Java [[BigSQLJava](./BigSQLJava)]

#### Hive

- Connect to Hive from Groovy [[Hive](./Hive)]
- Connect to Hive from Java  [[HiveJava](./HiveJava)]

#### Spark (run in a ssh session on the BigInsights cluster)

- Submit a python job [[SparkPythonSsh](./SparkPythonSsh)]
- Submit a Java job (coming soon ...)
- Submit a Scala job (coming soon ...)

#### Oozie (Using Knox API)

- Execute a Mapreduce job using Oozie [[OozieWorkflowMapReduce](./OozieWorkflowMapReduce)]
- Execute a Spark Java job using Oozie [[OozieWorkflowSpark](./OozieWorkflowSpark)]
- Execute a Spark Python job using Oozie [[OozieWorkflowSparkPython](./OozieWorkflowSparkPython)]

#### HBase

- Connect to HBase using Java [[HBaseJava](./HBaseJava)]
- Connect to HBase and create and manipulate a HBase table using Groovy [[HBase](./HBase)]

#### Kafka

- Connect to Kafka from Groovy (coming soon ...)
- Connect to Kafka from Java (coming soon ...)

####  Knox

- Run a knox shell client session [[Knoxshell](./Knoxshell)]
